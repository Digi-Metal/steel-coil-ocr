{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read images and labels to form dataset\n",
    "\n",
    "# Labels are: 0-9, A(10), B(11), C(12), F(13), G(14), T(15), ruido(16)\n",
    "\n",
    "# Insert dataset path and number of files to be read in each category\n",
    "datapath = 'D:\\\\UFES\\\\RevisionWorkstation\\\\TrainingFiles\\\\TopHatTrainingFiles\\\\'\n",
    "nfiles = [1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500]\n",
    "\n",
    "filenames = []\n",
    "for i in range(0,17):    \n",
    "    files = [fname for fname in glob.glob(datapath + str(i) + '\\\\*.png')]\n",
    "    files.sort\n",
    "    filenames = np.hstack((filenames, files[0:int(nfiles[i])]))\n",
    "\n",
    "\n",
    "filenames.sort\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 24100\n"
     ]
    }
   ],
   "source": [
    "# Read images and labels to form dataset\n",
    "filtering = True\n",
    "\n",
    "images = []\n",
    "rotulos = []\n",
    "\n",
    "if filtering:\n",
    "\n",
    "    input_shape = (180,120,1)\n",
    "    for fname in filenames:\n",
    "\n",
    "        # Get images\n",
    "        img = cv2.imread(fname, 0) \n",
    "        if img is not None:\n",
    "            img = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            # Get classification (using the folder name)\n",
    "            splits = fname.rsplit('\\\\', 2)\n",
    "\n",
    "            # Uptade Dataset\n",
    "            images.append(img)\n",
    "            rotulos.append(int(splits[1]))\n",
    "\n",
    "if not filtering:\n",
    "     \n",
    "    input_shape = (180,120,3)\n",
    "    for fname in filenames:\n",
    "\n",
    "        # Get images\n",
    "        img = cv2.imread(fname, 1) \n",
    "        if img is not None:\n",
    "          \n",
    "            # Get classification (using the folder name)\n",
    "            splits = fname.rsplit('\\\\', 2)\n",
    "\n",
    "            # Uptade Dataset\n",
    "            images.append(img)\n",
    "            rotulos.append(int(splits[1]))\n",
    "            \n",
    "print('Total number of images: ' + str(len(images)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform arrays\n",
    "if filtering:\n",
    "    images = np.array(images).reshape((len(images), 180, 120, 1))\n",
    "    rotulos = np.array(rotulos).reshape((len(rotulos), 1))\n",
    "if not filtering:\n",
    "    images = np.array(images).reshape((len(images), 180, 120, 3))\n",
    "    rotulos = np.array(rotulos).reshape((len(rotulos), 1))\n",
    "    \n",
    "# Normalize images\n",
    "images = images.astype('float32')\n",
    "rotulos = rotulos.astype('float32')\n",
    "\n",
    "images /= 255\n",
    "\n",
    "# Divide set to do single Holdout validation \n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "    \n",
    "# X_train (50%), X_valid(25%), X_test (25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, rotulos, test_size=0.25)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33)    \n",
    "\n",
    "# Converts a class vector (integers) to binary class matrix\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_valid = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "K.set_image_dim_ordering('th')\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquitetura: original\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 180, 120, 16)      160       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 180, 120, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 180, 120, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 90, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 90, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 45, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 43200)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 43200)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               22118912  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 17)                8721      \n",
      "=================================================================\n",
      "Total params: 22,134,753\n",
      "Trainable params: 22,134,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "arquitetura = 'Cifar'\n",
    "#arquitetura = 'VGG'\n",
    "#arquitetura = 'LeNet5'\n",
    "#arquitetura = 'AlexNet'\n",
    "\n",
    "if arquitetura == 'Cifar':\n",
    "\n",
    "    # Parameters\n",
    "    epochs = 20 \n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), input_shape=input_shape, padding = 'same', activation = 'relu', data_format='channels_last'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), data_format='channels_last'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3), padding = 'same', activation = 'relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), data_format='channels_last'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "if arquitetura == 'LeNet5':\n",
    "    #https://github.com/TaavishThaman/LeNet-5-with-Keras/blob/master/lenet_5.py\n",
    "    \n",
    "    # Parameters\n",
    "    epochs = 20\n",
    "    steps_per_epoch = 10\n",
    "    batch_size = 32\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(12, (5, 5), input_shape=input_shape, padding = 'same', data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2), padding = 'same'))\n",
    "   \n",
    "    model.add(Conv2D(25, (5, 5), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2), padding = 'same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units = 180, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(units = 100, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "if arquitetura == 'AlexNet':\n",
    "    #https://github.com/eweill/keras-deepcv/blob/master/models/classification/alexnet.py\n",
    "    \n",
    "    # Parameters\n",
    "    l2_reg=0.\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(96, (11, 11), input_shape=input_shape, padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = 'same'))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(256, (5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = 'same'))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = 'same'))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3072))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(4096))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "        \n",
    "print('Arquitetura: ' + arquitetura)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10979 samples, validate on 5409 samples\n",
      "Epoch 1/20\n",
      "10979/10979 [==============================] - 590s 54ms/step - loss: 0.1932 - acc: 0.9485 - val_loss: 0.1159 - val_acc: 0.9856\n",
      "Epoch 2/20\n",
      "10979/10979 [==============================] - 588s 54ms/step - loss: 0.0334 - acc: 0.9919 - val_loss: 0.0359 - val_acc: 0.9926\n",
      "Epoch 3/20\n",
      "10979/10979 [==============================] - 649s 59ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.0482 - val_acc: 0.9937\n",
      "Epoch 4/20\n",
      "10979/10979 [==============================] - 676s 62ms/step - loss: 0.0123 - acc: 0.9972 - val_loss: 0.0249 - val_acc: 0.9945\n",
      "Epoch 5/20\n",
      "10979/10979 [==============================] - 758s 69ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0232 - val_acc: 0.9950\n",
      "Epoch 6/20\n",
      "10979/10979 [==============================] - 765s 70ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0231 - val_acc: 0.9952\n",
      "Epoch 7/20\n",
      "10979/10979 [==============================] - 629s 57ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0357 - val_acc: 0.9930\n",
      "Epoch 8/20\n",
      "10979/10979 [==============================] - 629s 57ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0209 - val_acc: 0.9956\n",
      "Epoch 9/20\n",
      "10979/10979 [==============================] - 629s 57ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0234 - val_acc: 0.9945\n",
      "Epoch 10/20\n",
      "10979/10979 [==============================] - 629s 57ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0216 - val_acc: 0.9954\n",
      "Epoch 11/20\n",
      "10979/10979 [==============================] - 628s 57ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0230 - val_acc: 0.9957\n",
      "Epoch 12/20\n",
      "10979/10979 [==============================] - 628s 57ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0235 - val_acc: 0.9954\n",
      "Epoch 13/20\n",
      "10979/10979 [==============================] - 629s 57ms/step - loss: 4.5207e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9954\n",
      "Epoch 14/20\n",
      "10979/10979 [==============================] - 632s 58ms/step - loss: 6.2150e-04 - acc: 0.9998 - val_loss: 0.0241 - val_acc: 0.9959\n",
      "Epoch 15/20\n",
      "10979/10979 [==============================] - 652s 59ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0230 - val_acc: 0.9954\n",
      "Epoch 16/20\n",
      "10979/10979 [==============================] - 702s 64ms/step - loss: 2.9437e-04 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9959\n",
      "Epoch 17/20\n",
      "10979/10979 [==============================] - 15764s 1s/step - loss: 8.6602e-04 - acc: 0.9998 - val_loss: 0.0251 - val_acc: 0.9954\n",
      "Epoch 18/20\n",
      "10979/10979 [==============================] - 602s 55ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0257 - val_acc: 0.9952\n",
      "Epoch 19/20\n",
      "10979/10979 [==============================] - 574s 52ms/step - loss: 6.1930e-04 - acc: 0.9998 - val_loss: 0.0245 - val_acc: 0.9950\n",
      "Epoch 20/20\n",
      "10979/10979 [==============================] - 562s 51ms/step - loss: 7.0307e-04 - acc: 0.9997 - val_loss: 0.0256 - val_acc: 0.9950\n",
      "Accuracy: 99.50%\n"
     ]
    }
   ],
   "source": [
    "# Select place and name to save model\n",
    "modelName = 'D:\\\\UFES\\\\RevisionWorkstation\\\\modelCifarClahe'\n",
    "\n",
    "# Fit model to data set\n",
    "model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "# Evaluate model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# Save model\n",
    "model.save(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "alexsNet = load_model('D:\\\\UFES\\\\RevisionWorkstation\\\\modelAlexNetNoFilter')\n",
    "cifarNet = load_model('D:\\\\UFES\\\\RevisionWorkstation\\\\modelCifarNoFilter')\n",
    "lenetNet = load_model('D:\\\\UFES\\\\RevisionWorkstation\\\\modelLeNet5NoFilter')\n",
    "\n",
    "print(\"done loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccuracyAN: 98.70%\n",
      "AccuracyCF: 98.80%\n",
      "AccuracyLN: 98.77%\n"
     ]
    }
   ],
   "source": [
    "scores1 = alexsNet.evaluate(X_valid,y_valid,verbose=0)\n",
    "print(\"AccuracyAN: %.2f%%\" % (scores1[1]*100))\n",
    "\n",
    "scores2 = cifarNet.evaluate(X_valid,y_valid,verbose=0)\n",
    "print(\"AccuracyCF: %.2f%%\" % (scores2[1]*100))\n",
    "\n",
    "scores3 = lenetNet.evaluate(X_valid,y_valid,verbose=0)\n",
    "print(\"AccuracyLN: %.2f%%\" % (scores3[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:\\\\Thais Caldeira\\\\Imagens Bobinas\\\\Training Files\\\\9\\\\file_502.jpg\", 0) # gray\n",
    "img = cv2.threshold(img,10,255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "img = np.array(img).reshape((1, 180, 120, 1))\n",
    "\n",
    "img = img.astype('float32')\n",
    "\n",
    "img /= 255\n",
    "\n",
    "scores = model.predict(img)\n",
    "print(np.argmax(scores))\n",
    "scores = np.array(scores).reshape(16,1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chlib = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'F', 'G']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
